{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a94147f7",
   "metadata": {},
   "source": [
    "# Dendrite.ai Screening Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5cb40a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "LabelEncoder = LabelEncoder()\n",
    "from sklearn.feature_selection import RFE,SelectFromModel\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "grid =RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1c6c08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"C:\\\\Users\\\\mohit\\\\Downloads\\\\Screening Test - DS\\\\Screening Test\\\\algoparams_from_ui.json\", 'r')as file:\n",
    "    text =json.load(file)\n",
    "\n",
    "x = pd.DataFrame(text)\n",
    "dataset = x['design_state_data']['session_info']['dataset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a009c2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f040b9c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c5d0537",
   "metadata": {},
   "source": [
    "## 1)\tRead the target and type of regression to be run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aee228ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = x['design_state_data']['target']['target']\n",
    "prediction_type = x['design_state_data']['target']['type']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a84842",
   "metadata": {},
   "source": [
    "## 2) Read the features(which are column names in the csv) and figure out what missing imputation needs to be applied and apply that to the columns loaded in a dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c7f74312",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_handling  = x['design_state_data']['feature_handling']\n",
    "columns= []\n",
    "for k in feature_handling:\n",
    "    if (feature_handling[k]['is_selected'] == True) & (k!=target) :\n",
    "        columns.append(k)\n",
    "        if feature_handling[k]['feature_details'].get('impute_with') != None:\n",
    "            if feature_handling[k]['feature_details']['impute_with'] == 'Average of values':\n",
    "                df[k] = df[k].fillna((df[k].mean()))\n",
    "            elif feature_handling[k]['feature_details']['impute_with'] == \"custom\":\n",
    "                impute_value = feature_handling[k]['feature_details']['impute_value']\n",
    "                df[k] = df[k].fillna(impute_value)\n",
    "        if (feature_handling[k]['feature_variable_type'] == \"text\"):\n",
    "            df[k] =LabelEncoder.fit_transform(df[k])\n",
    "            \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27deeeb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9837e84a",
   "metadata": {},
   "source": [
    "## 3)\tCompute feature reduction based on input. See the screenshot below where there can be No Reduction, Corr with Target, Tree-based, PCA. Please make sure you write code so that all options can work. If we rerun your code with a different json it should work if we switch No Reduction to say PCA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f222a030",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_reduction = x['design_state_data']['feature_reduction']\n",
    "tr = df[columns]\n",
    "te = df[target]\n",
    "if (feature_reduction['feature_reduction_method'] == 'Tree-based'):\n",
    "    # With feature selection check auuracy with Random Forest\n",
    "    # The following example shows how to retrieve the 7 most informative features\n",
    "    model_tree = RandomForestRegressor(n_estimators = int(feature_reduction['num_of_trees']), max_depth =int(feature_reduction['depth_of_trees']))\n",
    "\n",
    "    # use RFE to eleminate the less importance features\n",
    "    sel_rfe_tree = RFE(estimator=model_tree, n_features_to_select=int(feature_reduction['num_of_features_to_keep']))\n",
    "    X_train_rfe_tree = sel_rfe_tree.fit_transform(tr, te)\n",
    "    selected_cols = [column for column in tr.columns if column in tr.columns[sel_rfe_tree.get_support()]]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4b546249",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = feature_reduction = x['design_state_data']['algorithms']\n",
    "hyperparameters = feature_reduction = x['design_state_data']['hyperparameters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75050ba5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bddfb18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 6 folds for each of 2 candidates, totalling 12 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=20, min_samples_leaf=8, n_estimators=14)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr = df[columns]\n",
    "te = df[target]\n",
    "X_train, X_test,y_train, y_test = train_test_split(tr,te,test_size=0.25, shuffle=True)\n",
    "for k in algorithm:\n",
    "    if (algorithm[k]['is_selected'] == True):\n",
    "        if (k == 'RandomForestRegressor'):\n",
    "            model = RandomForestRegressor()\n",
    "            mintrees = int(algorithm[k]['min_trees'])\n",
    "            maxtrees = int(algorithm[k]['max_trees'])\n",
    "            min_depth = int(algorithm[k]['min_depth'])\n",
    "            max_depth = int(algorithm[k]['max_depth'])\n",
    "            minleafsamplei = int(algorithm[k]['min_samples_per_leaf_min_value'])\n",
    "            minleafsamplej = int(algorithm[k]['min_samples_per_leaf_max_value'])\n",
    "            \n",
    "            forest_param = [{'n_estimators':list(range(mintrees, (maxtrees+1))),'max_depth': list(range(min_depth, (max_depth+1))), 'min_samples_leaf':list(range(minleafsamplei, (minleafsamplej+1)))}]\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a276188",
   "metadata": {},
   "source": [
    "## Run the fit and predict on each model  keep in mind that you need to do hyper parameter tuning i.e. use GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3a23bfad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 6 folds for each of 2 candidates, totalling 12 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=20, min_samples_leaf=8, n_estimators=14)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if (hyperparameters['stratergy'] == 'Grid Search'):\n",
    "    rf_random = grid(estimator = model, param_distributions = forest_param, n_iter = int(hyperparameters['max_iterations']), cv = int(hyperparameters['num_of_folds']), verbose=2, random_state=int(hyperparameters['random_state']), n_jobs = int(hyperparameters['parallelism']), scoring='neg_mean_squared_error')\n",
    "    \n",
    "    \n",
    "rf_random.fit(X_train, y_train)\n",
    "rf_random.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c3195c",
   "metadata": {},
   "source": [
    "## Log to the console the standard model metrics that apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "12959626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final RMSE on the test set is 0.19\n",
      "The best model achieves on the test set an accuracy of 82.75 %\n"
     ]
    }
   ],
   "source": [
    "final_model = rf_random.best_estimator_\n",
    "# Predicting test set results\n",
    "final_pred = final_model.predict(X_test)\n",
    "final_mse = mean_squared_error(y_test, final_pred)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "print('The final RMSE on the test set is', round(final_rmse, 2))\n",
    "#calculate accuracy\n",
    "errors = abs(final_pred - y_test)\n",
    "# Calculate mean absolute percentage error (MAPE)\n",
    "mape = np.mean(100 * (errors / y_test))\n",
    "# Calculate and display accuracy\n",
    "accuracy = 100 - mape    \n",
    "#print result\n",
    "print('The best model achieves on the test set an accuracy of', round(accuracy, 2),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b46cb61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875eb281",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
